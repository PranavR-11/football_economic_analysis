{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "INPUT_FILE  = \"5sznset_final.xlsx\"           # your raw merged panel file\n",
    "OUTPUT_FILE = \"5sznset_cleaned_full.xlsx\"    # cleaned, enriched output\n",
    "\n",
    "# === HELPER FUNCTIONS ===\n",
    "def clean_text(s):\n",
    "    \"\"\"Lowercase, strip, collapse whitespace.\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', str(s).lower().strip())\n",
    "\n",
    "def map_series(series, mapping):\n",
    "    \"\"\"Apply clean_text + mapping dict, then restore title‐case if needed.\"\"\"\n",
    "    return (series.fillna('')\n",
    "                  .apply(clean_text)\n",
    "                  .map(mapping)\n",
    "                  .fillna(series)\n",
    "                  .astype(str))\n",
    "\n",
    "# === FULL MAPPING DICTIONARIES ===\n",
    "# (Copied from your code above; add/remove entries as you refine)\n",
    "nation_mapping = {\n",
    "    \"eng eng\": \"England\", \"es esp\": \"Spain\", \"ie irl\": \"Ireland\", \"fr fra\": \"France\",\n",
    "    \"ma mar\": \"Morocco\", \"dz alg\": \"Algeria\", \"eg egy\": \"Egypt\", \"tn tun\": \"Tunisia\",\n",
    "    \"sa ksa\": \"Saudi Arabia\", \"de ger\": \"Germany\", \"it ita\": \"Italy\", \"pt por\": \"Portugal\",\n",
    "    \"nl ned\": \"Netherlands\", \"be bel\": \"Belgium\", \"ch sui\": \"Switzerland\", \"at aut\": \"Austria\",\n",
    "    \"dk den\": \"Denmark\", \"no nor\": \"Norway\", \"se swe\": \"Sweden\", \"pl pol\": \"Poland\",\n",
    "    \"cz cze\": \"Czech Republic\", \"sk svk\": \"Slovakia\", \"hu hun\": \"Hungary\",\n",
    "    \"ro rou\": \"Romania\", \"hr cro\": \"Croatia\", \"rs srb\": \"Serbia\",\n",
    "    \"ba bih\": \"Bosnia and Herzegovina\", \"bosnia-herzegovina\": \"Bosnia and Herzegovina\",\n",
    "    \"tr tur\": \"Turkey\", \"gr gre\": \"Greece\", \"us usa\": \"United States\", \"ca can\": \"Canada\",\n",
    "    \"mx mex\": \"Mexico\", \"ar arg\": \"Argentina\", \"br bra\": \"Brazil\", \"co col\": \"Colombia\",\n",
    "    \"uy uru\": \"Uruguay\", \"cl chi\": \"Chile\", \"pe per\": \"Peru\", \"gh gha\": \"Ghana\",\n",
    "    \"ci civ\": \"Ivory Coast\", \"cote d'ivoire\": \"Ivory Coast\", \"cm cmr\": \"Cameroon\",\n",
    "    \"sn sen\": \"Senegal\", \"ng nga\": \"Nigeria\", \"za rsa\": \"South Africa\",\n",
    "    \"jp jpn\": \"Japan\", \"cn chn\": \"China\", \"kr kor\": \"South Korea\", \"ir irn\": \"Iran\",\n",
    "    \"au aus\": \"Australia\", \"ph phi\": \"Philippines\", \"pr pur\": \"Puerto Rico\",\n",
    "    \"lt ltu\": \"Lithuania\", \"gp glp\": \"Guadeloupe\", \"mt mlt\": \"Malta\", \"ml mli\": \"Mali\",\n",
    "    \"gn gui\": \"Guinea\", \"gm gam\": \"The Gambia\", \"uz uzb\": \"Uzbekistan\", \"me mne\": \"Montenegro\",\n",
    "    \"is isl\": \"Iceland\", \"ru rus\": \"Russia\", \"al alb\": \"Albania\", \"ua ukr\": \"Ukraine\",\n",
    "    \"iq irq\": \"Iraq\", \"ly lby\": \"Libya\", \"sct sco\": \"Scotland\", \"cg cgo\": \"Congo\",\n",
    "    \"cd cod\": \"Democratic Republic Of The Congo\", \"py par\": \"Paraguay\", \"xk kvx\": \"Kosovo\",\n",
    "    \"nz nzl\": \"New Zealand\", \"si svn\": \"Slovenia\", \"gw gnb\": \"Guinea-Bissau\",\n",
    "    \"mk mkd\": \"North Macedonia\", \"wls wal\": \"Wales\", \"ge geo\": \"Georgia\",\n",
    "    \"ht hai\": \"Haiti\", \"ao ang\": \"Angola\", \"nir nir\": \"Northern Ireland\", \"bj ben\": \"Benin\",\n",
    "    \"cv cpv\": \"Cape Verde\", \"ve ven\": \"Venezuela\", \"tg tog\": \"Togo\", \"gf guf\": \"French Guiana\",\n",
    "    \"bf bfa\": \"Burkina Faso\", \"jm jam\": \"Jamaica\", \"fi fin\": \"Finland\", \"cf cta\": \"Central African Republic\",\n",
    "    \"cy cyp\": \"Cyprus\", \"am arm\": \"Armenia\", \"ga gab\": \"Gabon\", \"id idn\": \"Indonesia\",\n",
    "    \"ec ecu\": \"Ecuador\", \"gq eqg\": \"Equatorial Guinea\", \"sl sle\": \"Sierra Leone\",\n",
    "    \"ee est\": \"Estonia\", \"zm zam\": \"Zambia\", \"il isr\": \"Israel\"\n",
    "}\n",
    "\n",
    "club_mapping = {\n",
    "    'angers':'Angers Sco','arsenal':'Arsenal Fc','atalanta':'Atalanta Bc',\n",
    "    'athletic club':'Athletic Bilbao','atletico madrid':'Atlético De Madrid',\n",
    "    'augsburg':'Fc Augsburg','auxerre':'Aj Auxerre','barcelona':'Fc Barcelona',\n",
    "    'bayer leverkusen':'Bayer 04 Leverkusen','bochum':'Vfl Bochum',\n",
    "    'bologna':'Bologna Fc 1909','bournemouth':'Afc Bournemouth','brentford':'Brentford Fc',\n",
    "    'brest':'Stade Brestois 29','brighton':'Brighton & Hove Albion','cagliari':'Cagliari Calcio',\n",
    "    'celta vigo':'Celta De Vigo','chelsea':'Chelsea Fc','como':'Como 1907','empoli':'Fc Empoli',\n",
    "    'espanyol':'Rcd Espanyol Barcelona','everton':'Everton Fc','fiorentina':'Acf Fiorentina',\n",
    "    'freiburg':'Sc Freiburg','fulham':'Fulham Fc','genoa':'Genoa Cfc','getafe':'Getafe Cf',\n",
    "    'girona':'Girona Fc','heidenheim':'1.Fc Heidenheim 1846','hoffenheim':'Tsg 1899 Hoffenheim',\n",
    "    'juventus':'Juventus Fc','las palmas':'Ud Las Palmas','lazio':'Ss Lazio',\n",
    "    'le havre':'Le Havre Ac','lecce':'Us Lecce','leganes':'Cd Leganés','leicester':'Leicester City',\n",
    "    'leipzig':'Rb Leipzig','lens':'Rc Lens','lille':'Losc Lille','liverpool':'Liverpool Fc',\n",
    "    'lyon':'Olympique Lyon','mainz':'1.Fsv Mainz 05','mallorca':'Rcd Mallorca',\n",
    "    'marseille':'Olympique Marseille','monaco':'As Monaco','monchengladbach':'Borussia Mönchengladbach',\n",
    "    'montpellier':'Montpellier Hsc','monza':'Ac Monza','nantes':'Fc Nantes','napoli':'Ssc Napoli',\n",
    "    'newcastle':'Newcastle United','nice':'Ogc Nice','osasuna':'Ca Osasuna','parma':'Parma Calcio 1913',\n",
    "    'psg':'Paris Saint-Germain','real betis':'Real Betis Balompié','reims':'Stade Reims','rennes':'Stade Rennais Fc',\n",
    "    'roma':'As Roma','sevilla':'Sevilla Fc','southampton':'Southampton Fc','st pauli':'Fc St. Pauli',\n",
    "    'st-etienne':'As Saint-Étienne','strasbourg':'Rc Strasbourg Alsace','stuttgart':'Vfb Stuttgart',\n",
    "    'torino':'Torino Fc','tottenham':'Tottenham Hotspur','toulouse':'Fc Toulouse','udinese':'Udinese Calcio',\n",
    "    'union berlin':'1.Fc Union Berlin','valencia':'Valencia Cf','valladolid':'Real Valladolid Cf',\n",
    "    'venezia':'Venezia Fc','villarreal':'Villarreal Cf','werder bremen':'Sv Werder Bremen',\n",
    "    'west ham':'West Ham United','wolfsburg':'Vfl Wolfsburg','wolverhampton':'Wolverhampton Wanderers'\n",
    "}\n",
    "\n",
    "# === 1) LOAD & CLEAN COLUMN NAMES ===\n",
    "df = pd.read_excel(INPUT_FILE, engine=\"openpyxl\")\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.lower()\n",
    "      .str.strip()\n",
    "      .str.replace(r'[^\\w]+','_',regex=True)\n",
    "      .str.replace(r'__+','_',regex=True)\n",
    ")\n",
    "\n",
    "# === 2) TEXT CLEANING & MAPPING ===\n",
    "if 'player' in df: df['player'] = df['player'].apply(clean_text)\n",
    "if 'nation' in df: df['nation'] = map_series(df['nation'], nation_mapping).str.title()\n",
    "if 'squad'  in df: df['squad']  = map_series(df['squad'],  club_mapping).str.title()\n",
    "\n",
    "# === 3) FIX NUMERIC & MISSING ===\n",
    "# playing_time_min ← matches_played*90 if missing\n",
    "if 'playing_time_min' in df and 'matches_played' in df:\n",
    "    df['playing_time_min'] = df['playing_time_min'].fillna(df['matches_played']*90)\n",
    "\n",
    "# salary numeric\n",
    "if 'gross_p_w_(eur)' in df:\n",
    "    df['gross_p_w_(eur)'] = pd.to_numeric(df['gross_p_w_(eur)'],errors='coerce').fillna(0)\n",
    "\n",
    "# age_stats ← 2025 - born if missing\n",
    "if 'born' in df and 'age_stats' in df:\n",
    "    df['age_stats'] = df['age_stats'].fillna(2025 - pd.to_numeric(df['born'],errors='coerce'))\n",
    "\n",
    "# season unify\n",
    "if 'season_' in df and 'season' in df:\n",
    "    df['season'] = df['season'].fillna(df['season_'])\n",
    "elif 'season_' in df:\n",
    "    df['season'] = df['season_']\n",
    "df['season'] = df['season'].astype(str)\n",
    "\n",
    "# === 4) PROXY MARKET VALUE & LAG ===\n",
    "perf_col = 'performance_index' if 'performance_index' in df else 'rating_10'\n",
    "if perf_col in df:\n",
    "    df['proxy_market_value'] = (\n",
    "        df['gross_p_w_(eur)']*52 +\n",
    "        df[perf_col]*10000 +\n",
    "        df['age_stats']*1000\n",
    "    )\n",
    "else:\n",
    "    df['proxy_market_value'] = df['gross_p_w_(eur)']*52\n",
    "\n",
    "df = df.sort_values(['player','season'])\n",
    "df['market_value_lag'] = df.groupby('player')['proxy_market_value'].shift(1).fillna(0)\n",
    "\n",
    "# === 5) TRANSFER STATUS ===\n",
    "def transfer_status(gr):\n",
    "    gr = gr.sort_values('season')\n",
    "    prev_club = prev_season = None\n",
    "    status = []\n",
    "    for _,r in gr.iterrows():\n",
    "        c, s = r['squad'], r['season']\n",
    "        if prev_season==s and c!=prev_club:      status.append(1)\n",
    "        elif prev_season and int(s.split('-')[0])==int(prev_season.split('-')[0])+1 and c!=prev_club:\n",
    "            status.append(2)\n",
    "        else: status.append(0)\n",
    "        prev_club, prev_season = c,s\n",
    "    return pd.Series(status,index=gr.index)\n",
    "\n",
    "df['transfer_status'] = df.groupby('player',group_keys=False).apply(transfer_status)\n",
    "\n",
    "# === 6) HOMEGROWN / LOW‐PAID FLAG ===\n",
    "w_med = df['gross_p_w_(eur)'].median()\n",
    "df['homegrown_flag'] = ((df['age_stats']<20)&(df['playing_time_min']>=1000)).astype(int)\n",
    "df['low_paid_flag'] = (df['gross_p_w_(eur)']<w_med).astype(int)\n",
    "df['homegrown_or_lowpaid'] = ((df['homegrown_flag']|df['low_paid_flag'])).astype(int)\n",
    "\n",
    "# === 7) DEDUPE EXACT DUPLICATES ===\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# === 8) SAVE ===\n",
    "df.to_excel(OUTPUT_FILE, index=False, engine=\"openpyxl\")\n",
    "print(f\"✅ Done — cleaned data saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_excel(\"FINAL.xlsx\")\n",
    "\n",
    "# Filter out non-positive market values for log transformation\n",
    "df = df[df['proxy_market_value'] > 0].copy()\n",
    "df['log_market_value'] = np.log(df['proxy_market_value'])\n",
    "\n",
    "# Drop rows with critical NAs\n",
    "df = df.dropna(subset=[\n",
    "    'log_market_value', 'performance_score', 'adj._gross_(eur)', \n",
    "    'age_stats', 'homegrown_low_paid_flag', 'transfer_status'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       log_market_value   R-squared:                       0.746\n",
      "Model:                            OLS   Adj. R-squared:                  0.746\n",
      "Method:                 Least Squares   F-statistic:                     4157.\n",
      "Date:                Sat, 03 May 2025   Prob (F-statistic):               0.00\n",
      "Time:                        01:15:33   Log-Likelihood:                -11579.\n",
      "No. Observations:                8490   AIC:                         2.317e+04\n",
      "Df Residuals:                    8483   BIC:                         2.322e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      10.2242      0.069    148.101      0.000      10.089      10.360\n",
      "performance_score           0.4199      0.005     89.938      0.000       0.411       0.429\n",
      "adj._gross_(eur)         1.611e-07   4.31e-09     37.370      0.000    1.53e-07     1.7e-07\n",
      "homegrown_low_paid_flag    -1.4131      0.024    -59.013      0.000      -1.460      -1.366\n",
      "transfer_status             0.0912      0.014      6.410      0.000       0.063       0.119\n",
      "age_stats                   0.0030      0.003      1.207      0.228      -0.002       0.008\n",
      "interaction_perf_wage   -9.021e-09   1.19e-09     -7.586      0.000   -1.14e-08   -6.69e-09\n",
      "==============================================================================\n",
      "Omnibus:                     1806.586   Durbin-Watson:                   1.421\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4515.375\n",
      "Skew:                          -1.168   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.704   Cond. No.                     1.21e+08\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.21e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "✅ Regression complete. Output saved to 'consolidated_regression_output.txt'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# === Load dataset ===\n",
    "df = pd.read_excel(\"FINAL.xlsx\")\n",
    "\n",
    "# === Preprocessing ===\n",
    "# Ensure only valid market values\n",
    "df = df[df['proxy_market_value'] > 0].copy()\n",
    "\n",
    "# Log transform the dependent variable\n",
    "df['log_market_value'] = np.log(df['proxy_market_value'])\n",
    "\n",
    "# Create interaction term: performance × wage\n",
    "df['interaction_perf_wage'] = df['performance_score'] * df['adj._gross_(eur)']\n",
    "\n",
    "# Drop rows with missing data for any key variable\n",
    "model_df = df.dropna(subset=[\n",
    "    'log_market_value',\n",
    "    'performance_score',\n",
    "    'adj._gross_(eur)',\n",
    "    'age_stats',\n",
    "    'homegrown_low_paid_flag',\n",
    "    'transfer_status',\n",
    "    'interaction_perf_wage'\n",
    "])\n",
    "\n",
    "# === Define predictors and response ===\n",
    "X = model_df[[\n",
    "    'performance_score',\n",
    "    'adj._gross_(eur)',\n",
    "    'homegrown_low_paid_flag',\n",
    "    'transfer_status',\n",
    "    'age_stats',\n",
    "    'interaction_perf_wage'\n",
    "]]\n",
    "X = sm.add_constant(X)  # Adds intercept\n",
    "y = model_df['log_market_value']\n",
    "\n",
    "# === Run OLS Regression ===\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# === Output Summary ===\n",
    "print(model.summary())\n",
    "\n",
    "# === Save Output to File ===\n",
    "with open(\"consolidated_regression_output.txt\", \"w\") as f:\n",
    "    f.write(model.summary().as_text())\n",
    "\n",
    "print(\"✅ Regression complete. Output saved to 'consolidated_regression_output.txt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Variable        VIF\n",
      "0                         const  51.980815\n",
      "1             performance_score   1.696240\n",
      "2              adj._gross_(eur)   2.914996\n",
      "3                     age_stats   1.295236\n",
      "4       homegrown_low_paid_flag   1.394459\n",
      "5               transfer_status   1.010212\n",
      "6  performance_wage_interaction  50.379915\n",
      "7        proxy_market_value_lag  48.562542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel(\"FINAL.xlsx\")\n",
    "\n",
    "# Create interaction and lagged proxy value variables BEFORE dropna\n",
    "df['performance_wage_interaction'] = df['performance_score'] * df['adj._gross_(eur)']\n",
    "df['proxy_market_value_lag'] = df['adj._gross_(eur)'] * df['performance_score'] / (df['age_stats'] + 1)  # Example proxy\n",
    "\n",
    "# Define variables used in the final regression\n",
    "regression_vars = [\n",
    "    'performance_score',\n",
    "    'adj._gross_(eur)',\n",
    "    'age_stats',\n",
    "    'homegrown_low_paid_flag',\n",
    "    'transfer_status',\n",
    "    'performance_wage_interaction',\n",
    "    'proxy_market_value_lag'\n",
    "]\n",
    "\n",
    "# Drop rows with missing values in those columns\n",
    "df = df.dropna(subset=regression_vars + ['proxy_market_value'])\n",
    "\n",
    "# Create log-transformed dependent variable\n",
    "df['log_market_value'] = np.log(df['proxy_market_value'])\n",
    "\n",
    "# Prepare feature matrix for VIF (excluding DV)\n",
    "X = sm.add_constant(df[regression_vars])\n",
    "\n",
    "# Compute VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample anonymized dataset saved as 'anonymized_sample_2020_2025.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned DataFrame\n",
    "file_path = \"FINAL.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Select relevant columns for modeling and anonymization\n",
    "selected_cols = [\n",
    "    'rating_10',\n",
    "    'adj._gross_(eur)',\n",
    "    'age_stats',\n",
    "    'homegrown_low_paid_flag',\n",
    "    'transfer_status',\n",
    "    'proxy_market_value',\n",
    "    'market_value_lag'\n",
    "]\n",
    "\n",
    "# Drop NA and sample 500 random rows\n",
    "df_sample = df[selected_cols].dropna().sample(n=500, random_state=42)\n",
    "\n",
    "# Export to CSV\n",
    "df_sample.to_csv(\"anonymized_sample_2020_2025.csv\", index=False)\n",
    "print(\"✅ Sample anonymized dataset saved as 'anonymized_sample_2020_2025.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
